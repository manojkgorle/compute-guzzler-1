{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 From Scratch â€” Inference\n",
    "\n",
    "Load a trained GPT-2 checkpoint and generate text with different sampling strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment on Colab)\n",
    "# !pip install torch tiktoken datasets numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import GPT2Config, get_device\n",
    "from model import GPT2\n",
    "from generate import generate\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/best.pt\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "config = GPT2Config(**checkpoint[\"model_config\"])\n",
    "model = GPT2(config)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded from step {checkpoint.get('step', '?')}\")\n",
    "print(f\"Validation loss: {checkpoint.get('val_loss', '?'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Text\n",
    "\n",
    "Sampling parameters:\n",
    "- **temperature**: <1 = focused, >1 = creative (default 0.8)\n",
    "- **top_k**: keep top k tokens (default 50, 0 = disabled)\n",
    "- **top_p**: nucleus sampling threshold (default 0.95, 1.0 = disabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The meaning of life is\"\n",
    "\n",
    "output = generate(\n",
    "    model, prompt=prompt,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.8,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Sampling Strategies\n",
    "\n",
    "See how different temperature and top-k settings affect output quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In a shocking finding, scientists discovered\"\n",
    "\n",
    "settings = [\n",
    "    {\"temperature\": 0.3, \"top_k\": 10,  \"top_p\": 1.0,  \"label\": \"Conservative (T=0.3, k=10)\"},\n",
    "    {\"temperature\": 0.8, \"top_k\": 50,  \"top_p\": 0.95, \"label\": \"Balanced (T=0.8, k=50, p=0.95)\"},\n",
    "    {\"temperature\": 1.2, \"top_k\": 100, \"top_p\": 0.95, \"label\": \"Creative (T=1.2, k=100, p=0.95)\"},\n",
    "]\n",
    "\n",
    "for s in settings:\n",
    "    print(f\"--- {s['label']} ---\")\n",
    "    output = generate(\n",
    "        model, prompt=prompt,\n",
    "        max_new_tokens=100,\n",
    "        temperature=s[\"temperature\"],\n",
    "        top_k=s[\"top_k\"],\n",
    "        top_p=s[\"top_p\"],\n",
    "        device=device,\n",
    "    )\n",
    "    print(output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Generation\n",
    "\n",
    "Enter your own prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time\"  # <-- edit this\n",
    "\n",
    "output = generate(\n",
    "    model, prompt=prompt,\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.8,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
